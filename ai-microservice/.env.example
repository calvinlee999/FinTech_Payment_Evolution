# AI Inference Microservice Environment Configuration

# Server Configuration
PORT=3001
NODE_ENV=development

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://your-ai-foundry.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_API_VERSION=2024-10-21

# Redis Configuration (for caching)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Kafka Configuration (for event streaming)
KAFKA_BROKERS=localhost:9092
KAFKA_CLIENT_ID=ai-inference-service

# Application Insights (for monitoring)
APPINSIGHTS_CONNECTION_STRING=your-connection-string-here

# CORS Configuration
CORS_ORIGINS=http://localhost:3000,https://yourdomain.com

# Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=100
RATE_LIMIT_REQUESTS_PER_HOUR=1000

# Cache TTL (seconds)
CACHE_TTL_DEFAULT=3600
CACHE_TTL_EMBEDDINGS=86400

# Logging
LOG_LEVEL=info